<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 on Erik Wijmans</title>
    <link>https://wijmans.xyz/publication_types/1/</link>
    <description>Recent content in 1 on Erik Wijmans</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2020</copyright>
    <lastBuildDate>Sun, 22 Jan 2023 12:10:17 -0500</lastBuildDate>
    
	<atom:link href="https://wijmans.xyz/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Emergence of Maps in the Memories of Blind Navigation Agents</title>
      <link>https://wijmans.xyz/publication/eom/</link>
      <pubDate>Sun, 22 Jan 2023 12:10:17 -0500</pubDate>
      
      <guid>https://wijmans.xyz/publication/eom/</guid>
      <description>Introduction Decades of research into intelligent animal navigation posits that organisms build and maintain inter- nal spatial representations (or maps) of their environment, that enables the organism to determine and follow task-appropriate paths. Hamsters, wolves, chimpanzees, and bats leverage prior exploration to determine and follow short- cuts they may never have taken before. Even blind mole rats and animals rendered situationally-blind in dark environments demonstrate shortcut behaviors. Ants forage for food along meandering paths but take near-optimal return trips, though there is some controversy about whether insects like ants and bees are capable of forming maps.</description>
    </item>
    
    <item>
      <title>VER: Scaling On-Policy RL Leads to Emergence of Navigation in Embodied Rearrangement</title>
      <link>https://wijmans.xyz/publication/ver/</link>
      <pubDate>Sun, 28 Aug 2022 14:53:59 -0400</pubDate>
      
      <guid>https://wijmans.xyz/publication/ver/</guid>
      <description>Introduction How can we combine the benefit of synchronous (high sample efficiency) and asynchronous (high throughput) systems for batched on-policy reinforcement learning?
Systems for batched on-policy reinforcement learning collect experience from many (N) environments simultaneously using the policy and update it with this cumulative experience. They are broadly divided into two classes: synchronous (Sync) and asynchronous (Aync). Sync contains two synchronization points: first the policy is executed for the entire batch $(o_t \rightarrow a_t)^B_{b=1}$ (A), then actions are executed in all environments, $(s_t, a_t \rightarrow s_{t+1}, o_{t+1})^B_{b=1}$ (B), until $T$ steps have been collected from all $N$ environments.</description>
    </item>
    
    <item>
      <title>Is Mapping Necessary for Realistic PointGoal Navigation?</title>
      <link>https://wijmans.xyz/publication/mapping-for-pn/</link>
      <pubDate>Sat, 27 Aug 2022 15:05:01 -0400</pubDate>
      
      <guid>https://wijmans.xyz/publication/mapping-for-pn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Auxiliary Tasks and Exploration Enable ObjectNav</title>
      <link>https://wijmans.xyz/publication/aux-tasks-obj-nav/</link>
      <pubDate>Wed, 30 Jun 2021 11:13:34 -0400</pubDate>
      
      <guid>https://wijmans.xyz/publication/aux-tasks-obj-nav/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Megaverse: Simulating Embodied Agents at One Million Experiences per Second</title>
      <link>https://wijmans.xyz/publication/megaverse/</link>
      <pubDate>Wed, 30 Jun 2021 11:13:16 -0400</pubDate>
      
      <guid>https://wijmans.xyz/publication/megaverse/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DD-PPO: Learning Near-Perfect PointGoal Navigators from 2.5 Billion Frames</title>
      <link>https://wijmans.xyz/publication/ddppo-2019/</link>
      <pubDate>Thu, 26 Sep 2019 16:03:24 -0400</pubDate>
      
      <guid>https://wijmans.xyz/publication/ddppo-2019/</guid>
      <description>Introduction We present Decentralized Distributed PPO (DD-PPO). DD-PPO is synchronous and simple to implement. We leverage DD-PPO to achieve state of art results on the Habitat Autonomous Navigation Challenge 2019 and &amp;ldquo;solve&amp;rdquo; the task of PointGoal Navigation for agents with RGB-D and GPS+Compass sensors.
Specifically, these agents almost always reach the goal (failing on 1&amp;frasl;1000 val episodes on average), and reach it nearly as efficiently as possible &amp;ndash; nearly matching (within 3% of) the performance of a shortest-path oracle!</description>
    </item>
    
    <item>
      <title>Exploiting 2D Floorplan for Building-scale Panorama RGB-D Alignment</title>
      <link>https://wijmans.xyz/publication/building-scale-rgbd-alginment/</link>
      <pubDate>Sat, 22 Jul 2017 23:10:51 -0500</pubDate>
      
      <guid>https://wijmans.xyz/publication/building-scale-rgbd-alginment/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>