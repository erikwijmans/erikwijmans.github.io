+++
title = "Amodal 3D Bounding Box Prediction"
date = 2018-02-19T23:24:45-05:00
draft = true

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = []

# Project summary to display on homepage.
summary = "During Fall 2017, I worked on using PointNets to predict amodal 3D bounding boxes.  I saw initially promising results for regressing bounding boxes coordinates.  However, due to my desire to not use fixed anchors, the network had trouble determine which bounding boxes had an object."

# Optional image to display on homepage.
image_preview = ""

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Does the project detail page use source code highlighting?
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = ""
caption = ""


+++

I initially set out to use [PointNet](https://arxiv.org/abs/1612.00593)/[PointNet++](https://arxiv.org/abs/1706.02413) to
predict amodal 3D bounding boxes on point-clouds, utilizing the SUN RGB-D 3D dataset.  My approach was similar to that
of Faster R-CNN.  However, I did not want to descritize the search space and therefore attempted to use the points in the
point-clouds as anchors for the bounding boxes.  This approach ended up being too challenging for the network to easily learn.
[Frustum PointNet](https://arxiv.org/abs/1711.08488) presents a very interesting solution to this problem and leverages the 2D
rgb image to descritize the search space.

During this project, I gained a deep understand of PointNets and wrote of own implement of
[PointNet++ in PyTorch](https://github.com/erikwijmans/Pointnet2_PyTorch) so I could learn PyTorch and its CUDA
interoperability bridge.

